{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL son hal 2/6/22.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WvnmlPJryK3-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\"] # 11 options\n",
        "\n",
        "def load_imgs(dir):\n",
        "  lbls = [] #y\n",
        "  imgs = [] #X\n",
        "  for idx, lbl in enumerate(letters): #index, harf\n",
        "    for img in os.listdir(dir+\"/\"+lbl): #train_dir/A  \n",
        "      filepath = dir+\"/\"+lbl+\"/\"+img #train_dir/A/img1\n",
        "      image = cv2.resize(cv2.imread(filepath), (64,64))\n",
        "      imgs.append(image)\n",
        "      lbls.append(idx)\n",
        "  imgs = np.array(imgs)\n",
        "  lbls = np.array(lbls)\n",
        "  return (imgs, lbls)\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/ASLAlphabet/asl_alphabet_train/asl_alphabet_train\"\n",
        "images, labels = load_imgs(train_dir)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
        "X_train = (tf.cast(X_train, float))/255.\n",
        "X_test = (tf.cast(X_test, float))/255.\n",
        "\n",
        "IMG_SIZE = 64\n",
        "X_train = tf.reshape(X_train, (-1, IMG_SIZE, IMG_SIZE, 3))\n",
        "X_test = tf.reshape(X_test, (-1, IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
        "\n",
        "model = Sequential([\n",
        "                    # tf.keras.layers.InputLayer(),\n",
        "                    Conv2D(64, 5, padding=\"same\", activation=\"relu\", input_shape=(64, 64, 3)),\n",
        "                    Conv2D(64, 5, padding=\"same\", activation=\"relu\"),\n",
        "                    MaxPool2D(pool_size=(4,4)),\n",
        "                    Dropout(0.5),\n",
        "                    Conv2D(128, 5, padding=\"same\", activation=\"relu\"),\n",
        "                    Conv2D(128, 5, padding=\"same\", activation=\"relu\"),\n",
        "                    MaxPool2D(pool_size=(4,4)),\n",
        "                    Dropout(0.5),\n",
        "                    Conv2D(256, 5, padding=\"same\", activation=\"relu\"),\n",
        "                    Dropout(0.5),\n",
        "                    Flatten(),\n",
        "                    Dense(29, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "model.fit(X_train,y_train, \n",
        "          epochs=5, \n",
        "          validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "useEQb1uyPKv",
        "outputId": "ae3b7c95-caa9-4edd-fbbd-51c3ddc3a665"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "408/408 [==============================] - 1278s 3s/step - loss: 1.3370 - accuracy: 0.4335 - val_loss: 0.3544 - val_accuracy: 0.8614\n",
            "Epoch 2/5\n",
            "408/408 [==============================] - 1260s 3s/step - loss: 0.1893 - accuracy: 0.9350 - val_loss: 0.0343 - val_accuracy: 0.9899\n",
            "Epoch 3/5\n",
            "408/408 [==============================] - 1284s 3s/step - loss: 0.0643 - accuracy: 0.9798 - val_loss: 0.0172 - val_accuracy: 0.9982\n",
            "Epoch 4/5\n",
            "408/408 [==============================] - 1274s 3s/step - loss: 0.0416 - accuracy: 0.9874 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
            "Epoch 5/5\n",
            "408/408 [==============================] - 1249s 3s/step - loss: 0.0544 - accuracy: 0.9834 - val_loss: 0.0017 - val_accuracy: 0.9997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce2bbb35d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}